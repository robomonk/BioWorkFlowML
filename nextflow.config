// In your ~/BioWorkFlowML/nextflow.config file

// Define a parameter for an explicit pipeline name (optional)
// User can set this with: nextflow run ... --pipelineName my_cool_pipeline
params.pipelineName = 'pipeline' // Default if not provided

// Define a parameter for the data source (input file link/path)
params.dataSource = 'defaultSource' // Default value if not provided

// Get current timestamp
def timestamp = new java.text.SimpleDateFormat('yyyyMMdd_HHmmss').format(new Date())

// Determine the pipeline name for logging - uses param or a default
def pipelineLogName = (params.pipelineName as String).replaceAll("[^a-zA-Z0-9_.-]", "_")
if (pipelineLogName.isEmpty()) {
    pipelineLogName = "pipeline" // Ensure it's not empty
}

// Sanitize the dataSource parameter for use in a filename
def dataSourceActual = params.dataSource as String
def dataSourceBaseForName = dataSourceActual

if (!dataSourceActual.isEmpty()) {
    if (dataSourceActual.contains('/') || dataSourceActual.contains('\\')) {
        dataSourceBaseForName = new File(dataSourceActual).getName()
    }
}
if (dataSourceBaseForName.isEmpty()) {
    dataSourceBaseForName = 'default_source_id'
}
def finalDataSourceIdentifier = dataSourceBaseForName.replaceAll("[^a-zA-Z0-9_.-]", "_")
if (finalDataSourceIdentifier.isEmpty()) {
    finalDataSourceIdentifier = "source"
}

trace {
    enabled = true
    // Construct the log filename using only params and timestamp
    file = "logs/${pipelineLogName}-${finalDataSourceIdentifier}-${timestamp}.log"
    overwrite = false // Good practice, though unique names make it less critical
}

// Other configurations can go here
// process.executor = 'local'
// params.outdir = 'results'